{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restaurant Recommendation System\n",
    "\n",
    "## Base models for MVP (minimum viable product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import surprise libraries\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.prediction_algorithms import SVD, baseline_only\n",
    "from surprise.prediction_algorithms import KNNWithMeans, KNNBasic, KNNBaseline\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import accuracy, dataset\n",
    "from surprise.dataset import DatasetAutoFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rec Sys Modelling.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's read in our base review dataset\n",
    "df = pd.read_csv('../data/new_collaborative_limit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12552, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>business_ref</th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>categories</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>user_ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900</td>\n",
       "      <td>68</td>\n",
       "      <td>F31RycVVooeIOp9jsXmg6g</td>\n",
       "      <td>\"The Bluebird Cafe\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>Breakfast &amp; Brunch;Diners;Restaurants;Cafes;Br...</td>\n",
       "      <td>b31UZTy2TvnFtkfygJG40Q</td>\n",
       "      <td>bcxcQhp0sKYd9eUnEVUzPA</td>\n",
       "      <td>5</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>68</td>\n",
       "      <td>F31RycVVooeIOp9jsXmg6g</td>\n",
       "      <td>\"The Bluebird Cafe\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>Breakfast &amp; Brunch;Diners;Restaurants;Cafes;Br...</td>\n",
       "      <td>jYxWLyWrWy8dJFQs9DEuEg</td>\n",
       "      <td>RFxjYeLW_aYLdVW3PBwFNg</td>\n",
       "      <td>4</td>\n",
       "      <td>146572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1903</td>\n",
       "      <td>68</td>\n",
       "      <td>F31RycVVooeIOp9jsXmg6g</td>\n",
       "      <td>\"The Bluebird Cafe\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>Breakfast &amp; Brunch;Diners;Restaurants;Cafes;Br...</td>\n",
       "      <td>GGWxoYbx_h2x7a46m0MYRA</td>\n",
       "      <td>BhYROfCjIJsKUk22_IVHig</td>\n",
       "      <td>3</td>\n",
       "      <td>211139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1904</td>\n",
       "      <td>68</td>\n",
       "      <td>F31RycVVooeIOp9jsXmg6g</td>\n",
       "      <td>\"The Bluebird Cafe\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>Breakfast &amp; Brunch;Diners;Restaurants;Cafes;Br...</td>\n",
       "      <td>PslbThtGZ_yOWZxAFc3GVg</td>\n",
       "      <td>J_qpI2jCkwv7vPNz_9JeqA</td>\n",
       "      <td>4</td>\n",
       "      <td>260271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1907</td>\n",
       "      <td>68</td>\n",
       "      <td>F31RycVVooeIOp9jsXmg6g</td>\n",
       "      <td>\"The Bluebird Cafe\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>Breakfast &amp; Brunch;Diners;Restaurants;Cafes;Br...</td>\n",
       "      <td>oRYhx_qYK5slteB5nyEAiQ</td>\n",
       "      <td>NMelfYHO9mncdmZLIABLgQ</td>\n",
       "      <td>5</td>\n",
       "      <td>491834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  business_ref             business_id                 name  \\\n",
       "0        1900            68  F31RycVVooeIOp9jsXmg6g  \"The Bluebird Cafe\"   \n",
       "1        1901            68  F31RycVVooeIOp9jsXmg6g  \"The Bluebird Cafe\"   \n",
       "2        1903            68  F31RycVVooeIOp9jsXmg6g  \"The Bluebird Cafe\"   \n",
       "3        1904            68  F31RycVVooeIOp9jsXmg6g  \"The Bluebird Cafe\"   \n",
       "4        1907            68  F31RycVVooeIOp9jsXmg6g  \"The Bluebird Cafe\"   \n",
       "\n",
       "        city                                         categories  \\\n",
       "0  Edinburgh  Breakfast & Brunch;Diners;Restaurants;Cafes;Br...   \n",
       "1  Edinburgh  Breakfast & Brunch;Diners;Restaurants;Cafes;Br...   \n",
       "2  Edinburgh  Breakfast & Brunch;Diners;Restaurants;Cafes;Br...   \n",
       "3  Edinburgh  Breakfast & Brunch;Diners;Restaurants;Cafes;Br...   \n",
       "4  Edinburgh  Breakfast & Brunch;Diners;Restaurants;Cafes;Br...   \n",
       "\n",
       "                review_id                 user_id  stars  user_ref  \n",
       "0  b31UZTy2TvnFtkfygJG40Q  bcxcQhp0sKYd9eUnEVUzPA      5       246  \n",
       "1  jYxWLyWrWy8dJFQs9DEuEg  RFxjYeLW_aYLdVW3PBwFNg      4    146572  \n",
       "2  GGWxoYbx_h2x7a46m0MYRA  BhYROfCjIJsKUk22_IVHig      3    211139  \n",
       "3  PslbThtGZ_yOWZxAFc3GVg  J_qpI2jCkwv7vPNz_9JeqA      4    260271  \n",
       "4  oRYhx_qYK5slteB5nyEAiQ  NMelfYHO9mncdmZLIABLgQ      5    491834  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'business_ref', 'business_id', 'name', 'city',\n",
       "       'categories', 'review_id', 'user_id', 'stars', 'user_ref'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_ref</th>\n",
       "      <th>business_ref</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146572</td>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>211139</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>260271</td>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>491834</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_ref  business_ref  stars\n",
       "0       246            68      5\n",
       "1    146572            68      4\n",
       "2    211139            68      3\n",
       "3    260271            68      4\n",
       "4    491834            68      5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop out the columns we habve no use for. \n",
    "# ratings = df.drop(columns = ['Unnamed: 0', 'name', 'city', 'categories', 'review_id', ])\n",
    "ratings = df[['user_ref', 'business_ref', 'stars']]\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(dataset.DatasetAutoFolds):\n",
    "    #Creates data set that can be accessed by Surprise including folds for cross validation\n",
    "    \n",
    "    def __init__(self, df, reader):\n",
    "        \n",
    "        \n",
    "        self.raw_ratings = [(uid, iid, r, None) for (uid, iid, r) in zip(df['user_ref'], \n",
    "                                                                         df['business_ref'], df['stars'])]\n",
    "        self.reader=reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate an instance of Reader to enable surprise libraries to usethe data\n",
    "reader = Reader(rating_scale=(0.0, 5.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in our data to a surprise Dataset\n",
    "data = DataSet(ratings, reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into Train Validation and Split sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrace raw ratings from the dataset\n",
    "raw_ratings = data.raw_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform data shuffle\n",
    "random.shuffle(raw_ratings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll use a 80/20 train test ratio and 80/20 train validate ration. Train:Validate:Test - 64:16:20\n",
    "test_threshold = int(.8 * len(raw_ratings))\n",
    "\n",
    "train_raw_ratings = raw_ratings[:test_threshold] #create the train set\n",
    "test_raw_ratings = raw_ratings[test_threshold:] #creat the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_threshold = int(.8 * len(train_raw_ratings))\n",
    "\n",
    "val_raw_ratings = train_raw_ratings[val_threshold:] #create the validation set\n",
    "train_raw_ratings = train_raw_ratings[:val_threshold] #re_assign the training set\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we make the training set the data\n",
    "data.raw_ratings = train_raw_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory based collaborative filtering\n",
    "### We start with KNN Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll bring in some basic text stylin to help with output clarity. \n",
    "# start = \"\\033[1m\"\n",
    "# end = \"\\033[0;0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Knn_Basic(data, user, item):\n",
    "    '''\n",
    "    Function to run different similarity metrics across KNNBasic method. \n",
    "    \n",
    "    '''\n",
    "    frame = []\n",
    "    similarity_met = ['cosine', 'msd', 'pearson']\n",
    "    user_item= [True, False]\n",
    "    for i in similarity_met:\n",
    "            #user-user similarities\n",
    "            print(\"Evaluation of {} similarity for KNNBasic {} comparison: \". format(i, user))\n",
    "            results = cross_validate(KNNBasic(sim_options={'name': i, 'user_based': True}), \n",
    "                           data=data, cv=5, return_train_measures=True, n_jobs=-1, verbose = True)\n",
    "            print('\\n\\n')\n",
    "            \n",
    "            \n",
    "            \n",
    "            #item-item similarities\n",
    "            print(\"Evaluation of {} similarity for KNNBasic {} comparison: \". format(i, item))\n",
    "            results = cross_validate(KNNBasic(sim_options={'name': i, 'user_based': False}), \n",
    "                           data=data, cv=5, return_train_measures=True, n_jobs=-1, verbose = True)\n",
    "            print('\\n\\n')\n",
    "            \n",
    "            \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of cosine similarity for KNNBasic user-user comparison: \n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9835  0.9981  1.0251  1.0056  0.9814  0.9987  0.0160  \n",
      "MAE (testset)     0.7492  0.7646  0.7731  0.7713  0.7523  0.7621  0.0098  \n",
      "RMSE (trainset)   0.7734  0.7644  0.7572  0.7659  0.7674  0.7657  0.0052  \n",
      "MAE (trainset)    0.5836  0.5767  0.5723  0.5773  0.5760  0.5772  0.0037  \n",
      "Fit time          0.02    0.02    0.03    0.02    0.02    0.02    0.00    \n",
      "Test time         0.03    0.03    0.04    0.04    0.03    0.04    0.00    \n",
      "\n",
      "\n",
      "\n",
      "Evaluation of cosine similarity for KNNBasic item-item comparison: \n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0013  1.0260  1.0377  1.0238  1.0346  1.0247  0.0128  \n",
      "MAE (testset)     0.7678  0.7824  0.8111  0.7877  0.7919  0.7882  0.0141  \n",
      "RMSE (trainset)   0.8996  0.8963  0.8872  0.8924  0.8921  0.8935  0.0042  \n",
      "MAE (trainset)    0.7065  0.6976  0.6943  0.6990  0.7011  0.6997  0.0041  \n",
      "Fit time          0.19    0.20    0.20    0.21    0.29    0.22    0.04    \n",
      "Test time         0.09    0.08    0.10    0.10    0.09    0.09    0.01    \n",
      "\n",
      "\n",
      "\n",
      "Evaluation of msd similarity for KNNBasic user-user comparison: \n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9909  0.9895  1.0088  0.9785  1.0251  0.9986  0.0165  \n",
      "MAE (testset)     0.7625  0.7526  0.7726  0.7488  0.7823  0.7638  0.0124  \n",
      "RMSE (trainset)   0.5021  0.4991  0.4980  0.5001  0.4972  0.4993  0.0017  \n",
      "MAE (trainset)    0.3802  0.3779  0.3755  0.3776  0.3751  0.3773  0.0019  \n",
      "Fit time          0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n",
      "Test time         0.02    0.03    0.03    0.02    0.02    0.03    0.00    \n",
      "\n",
      "\n",
      "\n",
      "Evaluation of msd similarity for KNNBasic item-item comparison: \n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0092  1.0505  1.0114  1.0022  1.0213  1.0189  0.0169  \n",
      "MAE (testset)     0.7720  0.8110  0.7728  0.7667  0.7952  0.7835  0.0169  \n",
      "RMSE (trainset)   0.4903  0.4878  0.4915  0.4940  0.4875  0.4902  0.0024  \n",
      "MAE (trainset)    0.3541  0.3530  0.3556  0.3558  0.3526  0.3542  0.0013  \n",
      "Fit time          0.05    0.05    0.06    0.06    0.06    0.06    0.00    \n",
      "Test time         0.07    0.08    0.08    0.11    0.09    0.08    0.01    \n",
      "\n",
      "\n",
      "\n",
      "Evaluation of pearson similarity for KNNBasic user-user comparison: \n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9994  1.0166  1.0214  1.0021  1.0237  1.0126  0.0100  \n",
      "MAE (testset)     0.7719  0.7660  0.7835  0.7629  0.7978  0.7764  0.0128  \n",
      "RMSE (trainset)   0.4028  0.4090  0.4168  0.4130  0.4211  0.4125  0.0063  \n",
      "MAE (trainset)    0.2563  0.2567  0.2690  0.2629  0.2701  0.2630  0.0058  \n",
      "Fit time          0.03    0.03    0.03    0.03    0.03    0.03    0.00    \n",
      "Test time         0.03    0.02    0.02    0.03    0.02    0.02    0.00    \n",
      "\n",
      "\n",
      "\n",
      "Evaluation of pearson similarity for KNNBasic item-item comparison: \n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0258  1.0293  1.0886  1.0257  1.0578  1.0455  0.0247  \n",
      "MAE (testset)     0.7807  0.8014  0.8335  0.7964  0.8165  0.8057  0.0180  \n",
      "RMSE (trainset)   0.4710  0.4554  0.4729  0.4658  0.4649  0.4660  0.0061  \n",
      "MAE (trainset)    0.2997  0.2852  0.2997  0.2958  0.2956  0.2952  0.0053  \n",
      "Fit time          0.24    0.29    0.33    0.33    0.28    0.29    0.03    \n",
      "Test time         0.08    0.08    0.07    0.08    0.06    0.08    0.01    \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Knn_Basic(data, 'user-user', 'item-item')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNNBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Knn_Baseline(data, user, item):\n",
    "    '''\n",
    "    Function to run different similarity metrics across KNNBaseline method. \n",
    "    \n",
    "    '''\n",
    "    similarity_met = ['cosine', 'msd', 'pearson']\n",
    "    user_item= [True, False]\n",
    "    for i in similarity_met:\n",
    "            #user-user similarities\n",
    "            print(\"Evaluation of {} similarity for KNNBaseline {} comparison: \". format(i, user))\n",
    "            cross_validate(KNNBaseline(sim_options={'name': i, 'user_based': True}), \n",
    "                           data=data, cv=5, return_train_measures=True, n_jobs=-1, verbose = True)\n",
    "            print('\\n\\n')\n",
    "            \n",
    "            #item-item similarities\n",
    "            print(\"Evaluation of {} similarity for KNNBaseline {} comparison: \". format(i, item))\n",
    "            cross_validate(KNNBaseline(sim_options={'name': i, 'user_based': False}), \n",
    "                           data=data, cv=5, return_train_measures=True, n_jobs=-1, verbose = True)\n",
    "            print('\\n\\n')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of cosine similarity for KNNBaseline user-user comparison: \n",
      "Evaluating RMSE, MAE of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9787  0.9310  0.9304  0.9477  0.9623  0.9500  0.0186  \n",
      "MAE (testset)     0.7438  0.7162  0.7235  0.7314  0.7363  0.7302  0.0096  \n",
      "RMSE (trainset)   0.7226  0.7312  0.7311  0.7197  0.7222  0.7254  0.0048  \n",
      "MAE (trainset)    0.5495  0.5526  0.5529  0.5423  0.5470  0.5489  0.0039  \n",
      "Fit time          0.03    0.03    0.03    0.03    0.03    0.03    0.00    \n",
      "Test time         0.03    0.03    0.03    0.04    0.03    0.03    0.00    \n",
      "\n",
      "\n",
      "\n",
      "Evaluation of cosine similarity for KNNBaseline item-item comparison: \n",
      "Evaluating RMSE, MAE of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9530  0.9674  0.9561  0.9751  0.9506  0.9605  0.0093  \n",
      "MAE (testset)     0.7382  0.7406  0.7350  0.7471  0.7400  0.7402  0.0040  \n",
      "RMSE (trainset)   0.7991  0.8001  0.8037  0.7964  0.8003  0.7999  0.0024  \n",
      "MAE (trainset)    0.6202  0.6225  0.6245  0.6165  0.6214  0.6210  0.0027  \n",
      "Fit time          0.19    0.19    0.21    0.20    0.21    0.20    0.01    \n",
      "Test time         0.10    0.11    0.13    0.11    0.12    0.12    0.01    \n",
      "\n",
      "\n",
      "\n",
      "Evaluation of msd similarity for KNNBaseline user-user comparison: \n",
      "Evaluating RMSE, MAE of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9379  0.9569  0.9522  0.9849  0.9583  0.9580  0.0152  \n",
      "MAE (testset)     0.7229  0.7296  0.7363  0.7595  0.7414  0.7380  0.0124  \n",
      "RMSE (trainset)   0.4838  0.4815  0.4855  0.4815  0.4841  0.4832  0.0016  \n",
      "MAE (trainset)    0.3649  0.3665  0.3656  0.3658  0.3679  0.3661  0.0010  \n",
      "Fit time          0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n",
      "Test time         0.03    0.04    0.03    0.03    0.03    0.03    0.00    \n",
      "\n",
      "\n",
      "\n",
      "Evaluation of msd similarity for KNNBaseline item-item comparison: \n",
      "Evaluating RMSE, MAE of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9333  0.9599  0.9961  0.9627  0.9951  0.9694  0.0237  \n",
      "MAE (testset)     0.7124  0.7411  0.7664  0.7457  0.7625  0.7456  0.0192  \n",
      "RMSE (trainset)   0.4591  0.4608  0.4592  0.4607  0.4611  0.4602  0.0009  \n",
      "MAE (trainset)    0.3457  0.3444  0.3426  0.3443  0.3449  0.3444  0.0010  \n",
      "Fit time          0.06    0.06    0.07    0.07    0.07    0.07    0.00    \n",
      "Test time         0.09    0.11    0.10    0.12    0.14    0.11    0.02    \n",
      "\n",
      "\n",
      "\n",
      "Evaluation of pearson similarity for KNNBaseline user-user comparison: \n",
      "Evaluating RMSE, MAE of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9871  0.9587  0.9603  0.9921  0.9725  0.9742  0.0136  \n",
      "MAE (testset)     0.7596  0.7397  0.7392  0.7709  0.7551  0.7529  0.0121  \n",
      "RMSE (trainset)   0.3817  0.3763  0.3809  0.3711  0.3884  0.3797  0.0058  \n",
      "MAE (trainset)    0.2470  0.2429  0.2468  0.2406  0.2562  0.2467  0.0053  \n",
      "Fit time          0.03    0.03    0.04    0.04    0.03    0.03    0.00    \n",
      "Test time         0.03    0.03    0.02    0.02    0.02    0.02    0.00    \n",
      "\n",
      "\n",
      "\n",
      "Evaluation of pearson similarity for KNNBaseline item-item comparison: \n",
      "Evaluating RMSE, MAE of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9580  0.9847  0.9943  0.9818  0.9611  0.9760  0.0141  \n",
      "MAE (testset)     0.7382  0.7551  0.7680  0.7630  0.7385  0.7526  0.0123  \n",
      "RMSE (trainset)   0.3959  0.3819  0.3785  0.3851  0.3837  0.3850  0.0059  \n",
      "MAE (trainset)    0.2519  0.2428  0.2409  0.2462  0.2450  0.2454  0.0037  \n",
      "Fit time          0.23    0.25    0.26    0.32    0.30    0.27    0.03    \n",
      "Test time         0.06    0.08    0.08    0.08    0.08    0.08    0.01    \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Knn_Baseline(data, 'user-user', 'item-item')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNNWithMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Knn_With_Means(data, user, item):\n",
    "    '''\n",
    "    Function to run different similarity metrics across KNNBaseline method. \n",
    "    \n",
    "    '''\n",
    "    similarity_met = ['cosine', 'msd', 'pearson']\n",
    "    user_item= [True, False]\n",
    "    for i in similarity_met:\n",
    "            #user-user similarities\n",
    "            print(\"Evaluation of {} similarity for KNNBWithMeans {} comparison: \". format(i, user))\n",
    "            cross_validate(KNNWithMeans(sim_options={'name': i, 'user_based': True}), \n",
    "                           data=data, cv=5, return_train_measures=True, n_jobs=-1, verbose = True)\n",
    "            print('\\n\\n')\n",
    "            \n",
    "            #item-item similarities\n",
    "            print(\"Evaluation of {} similarity for KNNWithMeans {} comparison: \". format(i, item))\n",
    "            cross_validate(KNNWithMeans(sim_options={'name': i, 'user_based': False}), \n",
    "                           data=data, cv=5, return_train_measures=True, n_jobs=-1, verbose = True)\n",
    "            print('\\n\\n')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of cosine similarity for KNNBWithMeans user-user comparison: \n",
      "Evaluating RMSE, MAE of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9442  1.0083  0.9809  0.9523  0.9660  0.9704  0.0227  \n",
      "MAE (testset)     0.7264  0.7676  0.7522  0.7300  0.7313  0.7415  0.0159  \n",
      "RMSE (trainset)   0.7198  0.7093  0.7170  0.7240  0.7174  0.7175  0.0048  \n",
      "MAE (trainset)    0.5400  0.5363  0.5392  0.5413  0.5403  0.5394  0.0017  \n",
      "Fit time          0.03    0.03    0.03    0.03    0.02    0.03    0.00    \n",
      "Test time         0.03    0.03    0.03    0.03    0.03    0.03    0.00    \n",
      "\n",
      "\n",
      "\n",
      "Evaluation of cosine similarity for KNNWithMeans item-item comparison: \n",
      "Evaluating RMSE, MAE of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9965  0.9953  1.0099  0.9889  0.9953  0.9972  0.0069  \n",
      "MAE (testset)     0.7631  0.7639  0.7681  0.7644  0.7623  0.7644  0.0020  \n",
      "RMSE (trainset)   0.7142  0.7133  0.7051  0.7164  0.7140  0.7126  0.0039  \n",
      "MAE (trainset)    0.5449  0.5430  0.5418  0.5452  0.5457  0.5441  0.0015  \n",
      "Fit time          0.20    0.19    0.21    0.24    0.24    0.22    0.02    \n",
      "Test time         0.08    0.10    0.09    0.10    0.10    0.10    0.01    \n",
      "\n",
      "\n",
      "\n",
      "Evaluation of msd similarity for KNNBWithMeans user-user comparison: \n",
      "Evaluating RMSE, MAE of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9723  0.9782  0.9972  0.9719  0.9903  0.9820  0.0101  \n",
      "MAE (testset)     0.7598  0.7526  0.7604  0.7438  0.7473  0.7528  0.0066  \n",
      "RMSE (trainset)   0.5053  0.5053  0.5023  0.5063  0.5040  0.5046  0.0014  \n",
      "MAE (trainset)    0.3798  0.3796  0.3776  0.3824  0.3806  0.3800  0.0016  \n",
      "Fit time          0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n",
      "Test time         0.03    0.03    0.04    0.04    0.03    0.03    0.00    \n",
      "\n",
      "\n",
      "\n",
      "Evaluation of msd similarity for KNNWithMeans item-item comparison: \n",
      "Evaluating RMSE, MAE of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9871  0.9865  1.0038  1.0223  0.9846  0.9969  0.0145  \n",
      "MAE (testset)     0.7601  0.7655  0.7622  0.7816  0.7534  0.7646  0.0094  \n",
      "RMSE (trainset)   0.5249  0.5162  0.5194  0.5160  0.5192  0.5191  0.0032  \n",
      "MAE (trainset)    0.4016  0.3935  0.3986  0.3936  0.3958  0.3966  0.0031  \n",
      "Fit time          0.07    0.07    0.07    0.08    0.08    0.07    0.01    \n",
      "Test time         0.08    0.08    0.10    0.10    0.12    0.09    0.02    \n",
      "\n",
      "\n",
      "\n",
      "Evaluation of pearson similarity for KNNBWithMeans user-user comparison: \n",
      "Evaluating RMSE, MAE of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0100  0.9991  0.9769  0.9891  1.0221  0.9994  0.0157  \n",
      "MAE (testset)     0.7761  0.7718  0.7541  0.7629  0.7880  0.7706  0.0115  \n",
      "RMSE (trainset)   0.3749  0.3741  0.3725  0.3795  0.3715  0.3745  0.0027  \n",
      "MAE (trainset)    0.2406  0.2402  0.2432  0.2459  0.2420  0.2424  0.0020  \n",
      "Fit time          0.04    0.03    0.03    0.03    0.03    0.03    0.00    \n",
      "Test time         0.02    0.03    0.02    0.02    0.02    0.02    0.00    \n",
      "\n",
      "\n",
      "\n",
      "Evaluation of pearson similarity for KNNWithMeans item-item comparison: \n",
      "Evaluating RMSE, MAE of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9890  1.0146  1.0432  1.0175  1.0374  1.0203  0.0192  \n",
      "MAE (testset)     0.7508  0.7837  0.7966  0.7835  0.7842  0.7798  0.0153  \n",
      "RMSE (trainset)   0.3502  0.3423  0.3392  0.3490  0.3469  0.3455  0.0042  \n",
      "MAE (trainset)    0.2195  0.2100  0.2097  0.2165  0.2155  0.2143  0.0038  \n",
      "Fit time          0.24    0.25    0.30    0.28    0.31    0.28    0.03    \n",
      "Test time         0.06    0.08    0.08    0.08    0.06    0.07    0.01    \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Knn_With_Means(data, 'user-user', 'item-item')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the initial memory based model runs we can see that there is a preponderence of overfit training RMSE results and also less than spectacular test RMSE results. \n",
    "\n",
    "The best mean test RMSE is 0.9514 for KNN Baseline with cosine similarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition (SVD) with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Run 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surprise.model_selection.search.GridSearchCV"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_factors': [10, 50, 250], 'n_epochs':[5, 10, 15], 'lr_all': [0.002, 0.005, 0.01], \n",
    "              'reg_all':[0.005, 0.01, 0.05]}\n",
    "\n",
    "grid_search = GridSearchCV(SVD, param_grid=param_grid, measures=['rmse'],\n",
    "                           cv=5, n_jobs=-1, return_train_measures= True, joblib_verbose=5)\n",
    "        \n",
    "type(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 170 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 296 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:   47.9s finished\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.8951776277383795}\n",
      "{'rmse': {'n_factors': 10, 'n_epochs': 15, 'lr_all': 0.01, 'reg_all': 0.05}}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_score)\n",
    "print(grid_search.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Run 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surprise.model_selection.search.GridSearchCV"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's tune the n_factors, n_epochs and reg_all hyperparamters as the best fit is at the edges of the ranges\n",
    "param_grid = {'n_factors': [10, 50, 250], 'n_epochs':[12, 15, 17], 'lr_all': [0.002, 0.005, 0.01], \n",
    "              'reg_all':[0.005, 0.01, 0.05]}\n",
    "\n",
    "grid_search = GridSearchCV(SVD, param_grid=param_grid, measures=['rmse'],\n",
    "                           cv=5, n_jobs=-1, return_train_measures= True, joblib_verbose=5)\n",
    "        \n",
    "type(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:   53.2s finished\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.8978536126414325}\n",
      "{'rmse': {'n_factors': 10, 'n_epochs': 12, 'lr_all': 0.01, 'reg_all': 0.05}}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_score)\n",
    "print(grid_search.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Run 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:   42.2s finished\n"
     ]
    }
   ],
   "source": [
    "#Let's keep tuning as the RMSE is still reducing. \n",
    "param_grid = {'n_factors': [5, 10, 15], 'n_epochs':[15, 17, 20], 'lr_all': [0.002, 0.005, 0.01], \n",
    "              'reg_all':[0.01, 0.05, 0.1]}\n",
    "\n",
    "grid_search = GridSearchCV(SVD, param_grid=param_grid, measures=['rmse'],\n",
    "                           cv=5, n_jobs=-1, return_train_measures= True, joblib_verbose=5)\n",
    "        \n",
    "type(grid_search)\n",
    "grid_search.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.8946154343072017}\n",
      "{'rmse': {'n_factors': 10, 'n_epochs': 30, 'lr_all': 0.005, 'reg_all': 0.13}}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_score)\n",
    "print(grid_search.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Run 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:   47.5s finished\n"
     ]
    }
   ],
   "source": [
    "#And again we have achieved iterative improvement so we continue to tune. \n",
    "param_grid = {'n_factors': [8, 10, 12], 'n_epochs':[20, 25, 30], 'lr_all': [0.005, 0.01, 0.03], \n",
    "              'reg_all':[0.08, 0.11, 0.13]}\n",
    "\n",
    "opt_grid_search = GridSearchCV(SVD, param_grid=param_grid, measures=['rmse'],\n",
    "                           cv=5, n_jobs=-1, return_train_measures= True, joblib_verbose=5)\n",
    "        \n",
    "type(opt_grid_search)\n",
    "opt_grid_search.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.8943445484237433}\n",
      "{'rmse': {'n_factors': 8, 'n_epochs': 20, 'lr_all': 0.01, 'reg_all': 0.13}}\n"
     ]
    }
   ],
   "source": [
    "print(opt_grid_search.best_score)\n",
    "print(opt_grid_search.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our mean train RMSE achieved with SVD is:  0.668513554855789\n",
      "Our mean test RMSE achieved with SVD is:  0.9048012373045599\n"
     ]
    }
   ],
   "source": [
    "print('Our mean train RMSE achieved with SVD is: ', opt_grid_search.cv_results['mean_train_rmse'].mean())\n",
    "print('Our mean test RMSE achieved with SVD is: ', opt_grid_search.cv_results['mean_test_rmse'].mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the optimum output from run 4 we can see that the SVD model is overfitting and we report that there is instability in the model as on repeated runs we achieve small but potentially significant differences in the mean RMSE for both test and training sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorisation with Alternating Least Squares or Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible hyperparameter permutations:  125\n"
     ]
    }
   ],
   "source": [
    "#We would like to tune hyperparamters with GridSearchCV but let's see if we can automate the tuning.\n",
    "#We can tune items regularization(default=10), user regularization(def=15) and the numbe rof iterations(def=10).\n",
    "#We'll use the default values as the midpoint of our tuning range. \n",
    "epochs = [3, 8, 10, 12, 18]\n",
    "reg_u = [8, 10, 15, 20, 23]\n",
    "reg_i = [3, 8, 10, 12, 18]\n",
    "\n",
    "params = [[i, j, k] for i in epochs\n",
    "        for j in reg_u\n",
    "        for k in reg_i]\n",
    "print('Possible hyperparameter permutations: ', len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "bsl_options_scores = {}\n",
    "\n",
    "\n",
    "for bsl_perm in params:\n",
    "    bsl_options = {'method': 'als', \n",
    "                  'n_epochs': bsl_perm[0],\n",
    "                  'reg_u': bsl_perm[1],\n",
    "                  'reg_i': bsl_perm[2]}\n",
    "    \n",
    "    algo = baseline_only.BaselineOnly(bsl_options=bsl_options)\n",
    "    a = cross_validate(algo, data, measures=['RMSE'], cv=5, return_train_measures=True, verbose=False);\n",
    "    \n",
    "    bsl_perm_2 = (str(bsl_perm[0]) + ' ' + str(bsl_perm[1]) + ' ' + str(bsl_perm[2]))\n",
    "    bsl_options_scores[bsl_perm_2] = {'mean_train_rmse': a['train_rmse'].mean(), 'mean_test_rmse': a['test_rmse'].mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['18 8 3',\n",
       "  {'mean_train_rmse': 0.7673243043521893,\n",
       "   'mean_test_rmse': 0.8953178228259908}],\n",
       " ['10 8 3',\n",
       "  {'mean_train_rmse': 0.7674257476563309, 'mean_test_rmse': 0.89491710167036}],\n",
       " ['8 8 3',\n",
       "  {'mean_train_rmse': 0.7674921405559968,\n",
       "   'mean_test_rmse': 0.894750884106078}],\n",
       " ['3 8 3',\n",
       "  {'mean_train_rmse': 0.7677137943685581,\n",
       "   'mean_test_rmse': 0.8940072859741763}],\n",
       " ['12 8 3',\n",
       "  {'mean_train_rmse': 0.7677730287185669,\n",
       "   'mean_test_rmse': 0.8925432304414865}],\n",
       " ['3 10 3',\n",
       "  {'mean_train_rmse': 0.7704262895112967,\n",
       "   'mean_test_rmse': 0.8933606039139199}],\n",
       " ['10 10 3',\n",
       "  {'mean_train_rmse': 0.7704352235048366,\n",
       "   'mean_test_rmse': 0.8923360354528516}],\n",
       " ['12 10 3',\n",
       "  {'mean_train_rmse': 0.7705382107073901,\n",
       "   'mean_test_rmse': 0.8924810047366231}],\n",
       " ['8 10 3',\n",
       "  {'mean_train_rmse': 0.7707197802770637,\n",
       "   'mean_test_rmse': 0.8908434196070253}],\n",
       " ['18 10 3',\n",
       "  {'mean_train_rmse': 0.7709725852235743,\n",
       "   'mean_test_rmse': 0.8891247280882372}]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([[k, v] for k, v in bsl_options_scores.items()], key = lambda x: x[1]['mean_train_rmse'])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimimum hyperparameters are located on the edge of the ranges. We should retune to see if we can improve the rmse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible hyperparameter permutations:  80\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "#On the previous run we had an optimum result at 18, 8, 3. Lets reduce the range for reg_u and reg_i to see if there\n",
    "#is any room for improvement. \n",
    "epochs = [15, 18, 20, 25]\n",
    "reg_u = [3, 5, 8, 12, 15]\n",
    "reg_i = [2, 3, 4, 5]\n",
    "\n",
    "params = [[i, j, k] for i in epochs\n",
    "        for j in reg_u\n",
    "        for k in reg_i]\n",
    "print('Possible hyperparameter permutations: ', len(params))\n",
    "\n",
    "\n",
    "bsl_options_scores = {}\n",
    "\n",
    "\n",
    "for bsl_perm in params:\n",
    "    bsl_options = {'method': 'als', \n",
    "                  'n_epochs': bsl_perm[0],\n",
    "                  'reg_u': bsl_perm[1],\n",
    "                  'reg_i': bsl_perm[2]}\n",
    "    \n",
    "    algo = baseline_only.BaselineOnly(bsl_options=bsl_options)\n",
    "    a = cross_validate(algo, data, measures=['RMSE'], cv=5, return_train_measures=True, verbose=False);\n",
    "    \n",
    "    bsl_perm_2 = (str(bsl_perm[0]) + ' ' + str(bsl_perm[1]) + ' ' + str(bsl_perm[2]))\n",
    "    bsl_options_scores[bsl_perm_2] = {'mean_train_rmse': a['train_rmse'].mean(), 'mean_test_rmse': a['test_rmse'].mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['18 3 2',\n",
       "  {'mean_train_rmse': 0.7459371606876023,\n",
       "   'mean_test_rmse': 0.8988354307837444}],\n",
       " ['25 3 2',\n",
       "  {'mean_train_rmse': 0.7460140023486348,\n",
       "   'mean_test_rmse': 0.8976355578687425}],\n",
       " ['20 3 2',\n",
       "  {'mean_train_rmse': 0.746037943369531,\n",
       "   'mean_test_rmse': 0.8975171782947282}],\n",
       " ['15 3 2',\n",
       "  {'mean_train_rmse': 0.7464516572569412,\n",
       "   'mean_test_rmse': 0.8946660479627582}],\n",
       " ['18 5 2',\n",
       "  {'mean_train_rmse': 0.7491806414274294,\n",
       "   'mean_test_rmse': 0.8971870921957459}],\n",
       " ['20 5 2',\n",
       "  {'mean_train_rmse': 0.7494816391630076,\n",
       "   'mean_test_rmse': 0.8953220600628594}],\n",
       " ['25 5 2',\n",
       "  {'mean_train_rmse': 0.7496480992669531,\n",
       "   'mean_test_rmse': 0.8932157894255909}],\n",
       " ['15 5 2',\n",
       "  {'mean_train_rmse': 0.7496606687383481,\n",
       "   'mean_test_rmse': 0.8923352872873906}],\n",
       " ['18 8 2',\n",
       "  {'mean_train_rmse': 0.7537323317515915,\n",
       "   'mean_test_rmse': 0.8977543066290566}],\n",
       " ['15 8 2',\n",
       "  {'mean_train_rmse': 0.7538274663386846,\n",
       "   'mean_test_rmse': 0.8966326807721264}]]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([[k, v] for k, v in bsl_options_scores.items()], key = lambda x: x[1]['mean_train_rmse'])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attempt to improve the hyperparameters did not yield any improved results. in fact training data is slightly more overfit and the test RMSE is slightly worse. \n",
    "So we can progress using the preferred ALS model based filter as our current optimum model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9149  0.8892  0.8913  0.9069  0.8996  0.9004  0.0096  \n",
      "RMSE (trainset)   0.8217  0.8242  0.8236  0.8177  0.8216  0.8218  0.0023  \n",
      "Fit time          0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n",
      "Test time         0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n"
     ]
    }
   ],
   "source": [
    "#Let's run a cross validation based on the preferred ALS hyperparamters. \n",
    "best_bsl_option = {'method': 'als', \n",
    "                   'n_epochs': 8,\n",
    "                   'reg_u': 10, \n",
    "                   'reg_iu': 3}\n",
    "\n",
    "best_algo = baseline_only.BaselineOnly(bsl_options=best_bsl_option)\n",
    "best_cv = cross_validate(best_algo, data, measures=['rmse'], cv=5, verbose=True, return_train_measures=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Predictions and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.baseline_only.BaselineOnly at 0x1a1c6d5e80>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we now retrain on the whole training set ie training and validation together!\n",
    "trainset = data.build_full_trainset()\n",
    "best_algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testset = data.construct_testset(test_raw_ratings) #testset is now the test set sample as created at top of page\n",
    "# predictions = best_algo.test(testset)\n",
    "# print('Test set accuracy is: ', end=' ')\n",
    "# accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8977\n",
      "Validation set accuracy is: 0.8976725193728545\n"
     ]
    }
   ],
   "source": [
    "valset = data.construct_testset(val_raw_ratings)\n",
    "predictions = best_algo.test(valset)\n",
    "print('Validation set accuracy is: {}' .format(accuracy.rmse(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our original dataframe we can now undertake a quick comparison to see how our model would predict a small sample of from these know values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_ref</th>\n",
       "      <th>business_ref</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146572</td>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>211139</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>260271</td>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>491834</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1168645</td>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35710</td>\n",
       "      <td>380</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>77088</td>\n",
       "      <td>380</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>438436</td>\n",
       "      <td>380</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>590862</td>\n",
       "      <td>380</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_ref  business_ref  stars\n",
       "0       246            68      5\n",
       "1    146572            68      4\n",
       "2    211139            68      3\n",
       "3    260271            68      4\n",
       "4    491834            68      5\n",
       "5   1168645            68      4\n",
       "6     35710           380      5\n",
       "7     77088           380      4\n",
       "8    438436           380      5\n",
       "9    590862           380      4"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12552, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call our model and see what we would predict each user would rate for the given businesses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246    68     5     4.03     0.97\n",
      "146572    68     4     4.22     0.22\n",
      "211139    68     3     4.01     1.01\n",
      "260271    68     4     3.86     0.14\n",
      "491834    68     5     3.6     1.4\n",
      "1168645    68     4     3.76     0.24\n",
      "35710    380     5     4.01     0.99\n",
      "77088    380     4     3.99     0.01\n",
      "438436    380     5     4.06     0.94\n",
      "590862    380     4     3.78     0.22\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    prediction = round(best_algo.predict(uid = ratings.user_ref[i], iid = ratings.business_ref[i])[3], 2)\n",
    "    print(ratings.user_ref[i], '  ', ratings.business_ref[i], '   ', ratings.stars[i], '   ', \n",
    "         prediction, '   ', round(abs(ratings.stars[i]-prediction), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create table to show accuracy of current collaborative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_ref</th>\n",
       "      <th>business_ref</th>\n",
       "      <th>stars</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146572</td>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>211139</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>4.01</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>260271</td>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "      <td>3.86</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>491834</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1168645</td>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35710</td>\n",
       "      <td>380</td>\n",
       "      <td>5</td>\n",
       "      <td>4.01</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>77088</td>\n",
       "      <td>380</td>\n",
       "      <td>4</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>438436</td>\n",
       "      <td>380</td>\n",
       "      <td>5</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>590862</td>\n",
       "      <td>380</td>\n",
       "      <td>4</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_ref  business_ref  stars  Prediction  Difference\n",
       "0       246            68      5        4.03        0.97\n",
       "1    146572            68      4        4.22        0.22\n",
       "2    211139            68      3        4.01        1.01\n",
       "3    260271            68      4        3.86        0.14\n",
       "4    491834            68      5        3.60        1.40\n",
       "5   1168645            68      4        3.76        0.24\n",
       "6     35710           380      5        4.01        0.99\n",
       "7     77088           380      4        3.99        0.01\n",
       "8    438436           380      5        4.06        0.94\n",
       "9    590862           380      4        3.78        0.22"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred_df = ratings.copy().head(10)\n",
    "d = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "    prediction = round(best_algo.predict(uid = ratings.user_ref[i], iid = ratings.business_ref[i])[3], 2)\n",
    "    difference = round(abs(ratings.stars[i]-prediction), 2)\n",
    "#     print(ratings.user_ref[i], '  ', ratings.business_ref[i], '   ', ratings.stars[i], '   ', \n",
    "#          prediction, '   ', difference)\n",
    "    \n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Prediction': prediction,\n",
    "            'Difference': difference\n",
    "        \n",
    "        }, \n",
    "        index=[0]\n",
    "    \n",
    "    \n",
    "    )\n",
    "    \n",
    "    d = pd.concat([d, temp], axis=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "d = d.reset_index().drop(columns =['index'])\n",
    "\n",
    "pred_acc = pd.concat([pred_df, d], axis=1)\n",
    "pred_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected there is some variance in our predictions and we are ~0.6 of a point out on average across this small sample. On the scale we're working with that's an average of ~15% error on average but in worst case predictions we are ~27% out on the real world value. There is clearly some room for improvement here and we shall investigate further in the next phase of the project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build our base Recommenders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll progress to make a simple recommender based on this model. \n",
    "The following recommender may be a little crude for the purposes of recommending restaurants however it is a good kicking off point. It works by asking a new user to rate previous restaurants they may have visited and then offers them a basket of new restaurants that the may wish to visit.\n",
    "\n",
    "Future iterations of this model will likely ask a new user to rate how they feel about certain aspects of a restaurant that they would like to visits such as 'music', 'outdoor-seating', 'fish', 'chinese', 'cosy' etc etc. This approach together with taking the best rated / most popular restaurants will be one of the potential improvements that could be made. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to import a separate dataset to help with the next section. the dataframe should have three columns including\n",
    "#busniness_id, name, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>categories</th>\n",
       "      <th>business_ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>F31RycVVooeIOp9jsXmg6g</td>\n",
       "      <td>\"The Bluebird Cafe\"</td>\n",
       "      <td>Cannonmills</td>\n",
       "      <td>\"5 Canonmills\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>MLN</td>\n",
       "      <td>EH3 5HA</td>\n",
       "      <td>55.962444</td>\n",
       "      <td>-3.197662</td>\n",
       "      <td>4.5</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>Breakfast &amp; Brunch;Diners;Restaurants;Cafes;Br...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>380</td>\n",
       "      <td>inaACfObL1NBNJmBG11iuQ</td>\n",
       "      <td>\"Global Deli\"</td>\n",
       "      <td>Grassmarket</td>\n",
       "      <td>\"13 George IV Bridge, Old Town\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>EDH</td>\n",
       "      <td>EH1 1EE</td>\n",
       "      <td>55.947960</td>\n",
       "      <td>-3.192143</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>Restaurants;Food;Sandwiches;Coffee &amp; Tea;Delis</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             business_id                 name neighborhood  \\\n",
       "0          68  F31RycVVooeIOp9jsXmg6g  \"The Bluebird Cafe\"  Cannonmills   \n",
       "1         380  inaACfObL1NBNJmBG11iuQ        \"Global Deli\"  Grassmarket   \n",
       "\n",
       "                           address       city state postal_code   latitude  \\\n",
       "0                   \"5 Canonmills\"  Edinburgh   MLN     EH3 5HA  55.962444   \n",
       "1  \"13 George IV Bridge, Old Town\"  Edinburgh   EDH     EH1 1EE  55.947960   \n",
       "\n",
       "   longitude  stars  review_count  is_open  \\\n",
       "0  -3.197662    4.5            16        1   \n",
       "1  -3.192143    4.0            13        1   \n",
       "\n",
       "                                          categories  business_ref  \n",
       "0  Breakfast & Brunch;Diners;Restaurants;Cafes;Br...            68  \n",
       "1     Restaurants;Food;Sandwiches;Coffee & Tea;Delis           380  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants = pd.read_csv('../data/new_restaurants.csv')\n",
    "# print(restaurants.columns)\n",
    "restaurants.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Hanedan\"'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants.name.loc[1532] #our restaurant names have extra punctuation that needs removing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants.name = restaurants.name.str.replace('[^\\w\\s]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hanedan'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants.name.loc[1532]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_ref</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>The Bluebird Cafe</td>\n",
       "      <td>Breakfast &amp; Brunch, Diners, Restaurants, Cafes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>380</td>\n",
       "      <td>Global Deli</td>\n",
       "      <td>Restaurants, Food, Sandwiches, Coffee &amp; Tea, D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   business_ref               name  \\\n",
       "0            68  The Bluebird Cafe   \n",
       "1           380        Global Deli   \n",
       "\n",
       "                                          categories  \n",
       "0  Breakfast & Brunch, Diners, Restaurants, Cafes...  \n",
       "1  Restaurants, Food, Sandwiches, Coffee & Tea, D...  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rests = restaurants[['business_ref', 'name', 'categories']].replace({';':', '}, regex=True)\n",
    "rests.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     business_ref       name  \\\n",
      "143         15491  \"Amarone\"   \n",
      "\n",
      "                                            categories  \n",
      "143  Wine Bars, Italian, Nightlife, Restaurants, Br...  \n",
      "how do you rate this restaurant on a scale of 1-5, press n if you don't know:\n",
      "1\n",
      "      business_ref            name  \\\n",
      "1383        151334  \"Cafe Artista\"   \n",
      "\n",
      "                                             categories  \n",
      "1383  Food, Coffee & Tea, Seafood, Pizza, Restaurant...  \n",
      "how do you rate this restaurant on a scale of 1-5, press n if you don't know:\n",
      "2\n",
      "      business_ref            name            categories\n",
      "1006        110035  \"La Rusticana\"  Restaurants, Italian\n",
      "how do you rate this restaurant on a scale of 1-5, press n if you don't know:\n",
      "3\n",
      "     business_ref                            name                   categories\n",
      "477         52185  \"Dominic's Italian Restaurant\"  Delis, Restaurants, Italian\n",
      "how do you rate this restaurant on a scale of 1-5, press n if you don't know:\n",
      "1\n",
      "     business_ref             name            categories\n",
      "566         60258  \"La Bruschetta\"  Restaurants, Italian\n",
      "how do you rate this restaurant on a scale of 1-5, press n if you don't know:\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def restaurant_rater(df, num, category=None):\n",
    "    userID = 2011\n",
    "    ratings_info = []\n",
    "    \n",
    "    while num > 0:\n",
    "        if category:\n",
    "            restaurant = df[df['categories'].str.contains(category)].sample(1)\n",
    "        else:\n",
    "            restaurant = df.sample(1)\n",
    "        print(restaurant)\n",
    "        rating = input(\"how do you rate this restaurant on a scale of 1-5, press n if you don't know:\\n\")\n",
    "        \n",
    "        if rating == 'n':\n",
    "            continue\n",
    "        else: \n",
    "            rating_one_restaurant = {'user_ref': userID, 'business_ref':restaurant['business_ref'].values[0],\n",
    "                                     'stars': rating}\n",
    "            ratings_info.append(rating_one_restaurant)\n",
    "            num-=1\n",
    "    return ratings_info\n",
    "\n",
    "user_rating = restaurant_rater(rests, 5, 'Italian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ratings_df = ratings.append(user_rating, ignore_index=True)\n",
    "new_data = Dataset.load_from_df(new_ratings_df, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1a1da43710>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_ = SVD(n_factors=5, reg_all=0.02)\n",
    "svd_.fit(new_data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_algo.fit(new_data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_restaurants = []\n",
    "for rest in ratings['business_ref'].unique():\n",
    "    list_of_restaurants.append((rest, svd_.predict(2011,rest)[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(85492, 4.001916537117831),\n",
       " (49357, 3.998111102967452),\n",
       " (166894, 3.9779367818953446),\n",
       " (99404, 3.9169584748558672),\n",
       " (10769, 3.913866662814472),\n",
       " (70513, 3.8542467782417877),\n",
       " (157250, 3.844907522454616),\n",
       " (134710, 3.834878505760527),\n",
       " (150652, 3.833452097016452),\n",
       " (22594, 3.8077370010650555)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_recommended = sorted(list_of_restaurants, key=lambda x:x[1], reverse=True)\n",
    "ranked_recommended[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we want to be able to return the actual restaurant names not just the id's from the ratings df. We'll write a function to extract this information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation #  1 :  773    \"Field\"\n",
      "Name: name, dtype: object \n",
      "\n",
      "Recommendation #  2 :  450    \"Martin Wishart\"\n",
      "Name: name, dtype: object \n",
      "\n",
      "Recommendation #  3 :  1532    \"Hanedan\"\n",
      "Name: name, dtype: object \n",
      "\n",
      "Recommendation #  4 :  895    \"The Scotch Malt Whisky Society\"\n",
      "Name: name, dtype: object \n",
      "\n",
      "Recommendation #  5 :  95    \"Royal Mile\"\n",
      "Name: name, dtype: object \n",
      "\n",
      "Recommendation #  6 :  653    \"Hotel Chocolat Cafe\"\n",
      "Name: name, dtype: object \n",
      "\n",
      "Recommendation #  7 :  1448    \"Patisserie Madeleine\"\n",
      "Name: name, dtype: object \n",
      "\n",
      "Recommendation #  8 :  1253    \"Noor Indian Takeaway\"\n",
      "Name: name, dtype: object \n",
      "\n",
      "Recommendation #  9 :  1378    \"Kismot\"\n",
      "Name: name, dtype: object \n",
      "\n",
      "Recommendation #  10 :  212    \"Soul Sushi\"\n",
      "Name: name, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# return the top n recommendations \n",
    "def restaurant_recommender(user_ratings, restaurant_name_df, n):\n",
    "    '''\n",
    "    function returns the top recommended restaurants\n",
    "    '''\n",
    "    for index, rec in enumerate(user_ratings):\n",
    "        name = restaurant_name_df.loc[restaurant_name_df['business_ref'] == int(rec[0])]['name']\n",
    "        print('Recommendation # ', index+1, ': ', name, '\\n')\n",
    "        n-=1\n",
    "        if n == 0:\n",
    "            break\n",
    "restaurant_recommender(ranked_recommended, rests, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a number of runs we are consistently being returned the same or similar list of recommendation. We suspect that only asking for five ratings is not having enough impact in the sparse matrix and we are simply being recommended the highest rated and or most popular restaurants in the area. Let's test this theory...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>categories</th>\n",
       "      <th>business_ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>166894</td>\n",
       "      <td>WAMesuyxdmL3SRigsxlXng</td>\n",
       "      <td>\"Hanedan\"</td>\n",
       "      <td>Newington</td>\n",
       "      <td>\"41-42 West Preston Street\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>EDH</td>\n",
       "      <td>EH8 9PY</td>\n",
       "      <td>55.938891</td>\n",
       "      <td>-3.181186</td>\n",
       "      <td>5.0</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>Turkish;Restaurants</td>\n",
       "      <td>166894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0             business_id       name neighborhood  \\\n",
       "1532      166894  WAMesuyxdmL3SRigsxlXng  \"Hanedan\"    Newington   \n",
       "\n",
       "                          address       city state postal_code   latitude  \\\n",
       "1532  \"41-42 West Preston Street\"  Edinburgh   EDH     EH8 9PY  55.938891   \n",
       "\n",
       "      longitude  stars  review_count  is_open           categories  \\\n",
       "1532  -3.181186    5.0            57        1  Turkish;Restaurants   \n",
       "\n",
       "      business_ref  \n",
       "1532        166894  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We're getting similar recommendations for every run - let's look at the individual restaurants\n",
    "restaurants[restaurants['name'].str.match('\"Hanedan\"')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Hanedan has an average 5 stars and has a high review count in relation to the whole set. This implies our theory might be relevant so let's check all the restaurants in the top ranked set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[85492, 49357, 166894, 99404, 10769, 70513, 157250, 134710, 150652, 22594]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract the business refs in ranked_recommended\n",
    "ranked_refs = [x[0] for x in ranked_recommended[:10]]\n",
    "ranked_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Royal Mile',\n",
       " 'Soul Sushi',\n",
       " 'Martin Wishart',\n",
       " 'Hotel Chocolat Cafe',\n",
       " 'Field',\n",
       " 'The Scotch Malt Whisky Society',\n",
       " 'Noor Indian Takeaway',\n",
       " 'Kismot',\n",
       " 'Patisserie Madeleine',\n",
       " 'Hanedan']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Return the names associated with these refs into a list\n",
    "rec_list = []\n",
    "for index, row in rests.iterrows():\n",
    "    if row['business_ref'] in ranked_refs:\n",
    "#         print(row['name'])\n",
    "        rec_list.append(row['name'])\n",
    "rec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Royal Mile has 4.5 stars and 99 reviews\n",
      "Soul Sushi has 4.5 stars and 20 reviews\n",
      "Martin Wishart has 5.0 stars and 24 reviews\n",
      "Hotel Chocolat Cafe has 4.5 stars and 45 reviews\n",
      "Field has 4.5 stars and 41 reviews\n",
      "The Scotch Malt Whisky Society has 5.0 stars and 26 reviews\n",
      "The Scotch Malt Whisky Society has 4.5 stars and 26 reviews\n",
      "Noor Indian Takeaway has 4.5 stars and 40 reviews\n",
      "Kismot has 4.5 stars and 48 reviews\n",
      "Patisserie Madeleine has 5.0 stars and 21 reviews\n",
      "Hanedan has 5.0 stars and 57 reviews\n"
     ]
    }
   ],
   "source": [
    "for i in rec_list:\n",
    "    for index, row in restaurants.iterrows():\n",
    "        if row['name'] == i:\n",
    "            print(row['name'], 'has', row['stars'], 'stars and', row['review_count'], 'reviews')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see as suspected that all the recommended restaurants have a very high average rating and also high relative review counts. When recommendations are only based on a small user review set our collaborative recommender will normally just return the best restaurants in Edinburgh. This is currently operating as a basic cold start recommender. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Based Models\n",
    "### Get most similar restaurants based on categorical and review information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1605, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>categories</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>F31RycVVooeIOp9jsXmg6g</td>\n",
       "      <td>\"The Bluebird Cafe\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>Breakfast &amp; Brunch, Diners, Restaurants, Cafes...</td>\n",
       "      <td>When Blythe told me he'd checked out a new spo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>380</td>\n",
       "      <td>inaACfObL1NBNJmBG11iuQ</td>\n",
       "      <td>\"Global Deli\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>Restaurants, Food, Sandwiches, Coffee &amp; Tea, D...</td>\n",
       "      <td>Global Deli is a great find if you're feeling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>397</td>\n",
       "      <td>Di5ApLgoQpcv5Aew82fI_A</td>\n",
       "      <td>\"The Rendezvous\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>Restaurants, Cantonese, Chinese</td>\n",
       "      <td>Not been to this restaurant for about 2 years ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>420</td>\n",
       "      <td>OvbLKXkJCg8ZMHX9L5faIA</td>\n",
       "      <td>\"Bread Meats Bread\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>Burgers, Restaurants</td>\n",
       "      <td>I know people rave about this place so I'm sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>446</td>\n",
       "      <td>T2jfXhvQPk9wLdt1OVV-Kg</td>\n",
       "      <td>\"Rose Street Brewery\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>Pubs, Whiskey Bars, Nightlife, Breakfast &amp; Bru...</td>\n",
       "      <td>One of many spots on Rose St. A good variety o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             business_id                   name       city  \\\n",
       "0          68  F31RycVVooeIOp9jsXmg6g    \"The Bluebird Cafe\"  Edinburgh   \n",
       "1         380  inaACfObL1NBNJmBG11iuQ          \"Global Deli\"  Edinburgh   \n",
       "2         397  Di5ApLgoQpcv5Aew82fI_A       \"The Rendezvous\"  Edinburgh   \n",
       "3         420  OvbLKXkJCg8ZMHX9L5faIA    \"Bread Meats Bread\"  Edinburgh   \n",
       "4         446  T2jfXhvQPk9wLdt1OVV-Kg  \"Rose Street Brewery\"  Edinburgh   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Breakfast & Brunch, Diners, Restaurants, Cafes...   \n",
       "1  Restaurants, Food, Sandwiches, Coffee & Tea, D...   \n",
       "2                    Restaurants, Cantonese, Chinese   \n",
       "3                               Burgers, Restaurants   \n",
       "4  Pubs, Whiskey Bars, Nightlife, Breakfast & Bru...   \n",
       "\n",
       "                                                text  \n",
       "0  When Blythe told me he'd checked out a new spo...  \n",
       "1  Global Deli is a great find if you're feeling ...  \n",
       "2  Not been to this restaurant for about 2 years ...  \n",
       "3  I know people rave about this place so I'm sur...  \n",
       "4  One of many spots on Rose St. A good variety o...  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/content.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our minimum viable product we will utilise the categorical data to find similarities between restaurants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>categories</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>F31RycVVooeIOp9jsXmg6g</td>\n",
       "      <td>\"The Bluebird Cafe\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>breakfast &amp; brunch, diners, restaurants, cafes...</td>\n",
       "      <td>When Blythe told me he'd checked out a new spo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>380</td>\n",
       "      <td>inaACfObL1NBNJmBG11iuQ</td>\n",
       "      <td>\"Global Deli\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>restaurants, food, sandwiches, coffee &amp; tea, d...</td>\n",
       "      <td>Global Deli is a great find if you're feeling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>397</td>\n",
       "      <td>Di5ApLgoQpcv5Aew82fI_A</td>\n",
       "      <td>\"The Rendezvous\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>restaurants, cantonese, chinese</td>\n",
       "      <td>Not been to this restaurant for about 2 years ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>420</td>\n",
       "      <td>OvbLKXkJCg8ZMHX9L5faIA</td>\n",
       "      <td>\"Bread Meats Bread\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>burgers, restaurants</td>\n",
       "      <td>I know people rave about this place so I'm sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>446</td>\n",
       "      <td>T2jfXhvQPk9wLdt1OVV-Kg</td>\n",
       "      <td>\"Rose Street Brewery\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>pubs, whiskey bars, nightlife, breakfast &amp; bru...</td>\n",
       "      <td>One of many spots on Rose St. A good variety o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             business_id                   name       city  \\\n",
       "0          68  F31RycVVooeIOp9jsXmg6g    \"The Bluebird Cafe\"  Edinburgh   \n",
       "1         380  inaACfObL1NBNJmBG11iuQ          \"Global Deli\"  Edinburgh   \n",
       "2         397  Di5ApLgoQpcv5Aew82fI_A       \"The Rendezvous\"  Edinburgh   \n",
       "3         420  OvbLKXkJCg8ZMHX9L5faIA    \"Bread Meats Bread\"  Edinburgh   \n",
       "4         446  T2jfXhvQPk9wLdt1OVV-Kg  \"Rose Street Brewery\"  Edinburgh   \n",
       "\n",
       "                                          categories  \\\n",
       "0  breakfast & brunch, diners, restaurants, cafes...   \n",
       "1  restaurants, food, sandwiches, coffee & tea, d...   \n",
       "2                    restaurants, cantonese, chinese   \n",
       "3                               burgers, restaurants   \n",
       "4  pubs, whiskey bars, nightlife, breakfast & bru...   \n",
       "\n",
       "                                                text  \n",
       "0  When Blythe told me he'd checked out a new spo...  \n",
       "1  Global Deli is a great find if you're feeling ...  \n",
       "2  Not been to this restaurant for about 2 years ...  \n",
       "3  I know people rave about this place so I'm sur...  \n",
       "4  One of many spots on Rose St. A good variety o...  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['categories'] = df['categories'].str.lower()\n",
    "df['categories'] = df['categories'].apply(lambda x: x.strip())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Crazy Ivans\"'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.name.loc[302] #too much punctuation in the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Crazy Ivans'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.name = df.name.str.replace('[^\\w\\s]', '') #Remove problematic speech marks\n",
    "df.name.loc[302]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from the restauranty EDA that there are some high frequency category words which we don't want for modelling purposes. This is because they don't tell us anything specific about the establishment.\\\n",
    "The words we'll remove on this initial run are 'Restaurant' & 'Food'. We have to assume that the establishments in question are 'restaurants' as that's a condition of entry into the dataset and 'food' as that's a condition of being a restaurant! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create required stop words list\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "add_stopwords = ['restaurants', 'food']\n",
    "stopwords.extend(add_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     0\n",
       "business_id    0\n",
       "name           0\n",
       "city           0\n",
       "categories     0\n",
       "text           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() #double check no NANS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of the TFidFVectorizer class and pass in parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(min_df=3, max_df=1600, max_features=None, strip_accents='unicode', \n",
    "                    analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,2), stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit and transform the instance on the restaurant's categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfv_matrix = tfv.fit_transform(df['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1605, 396)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1605x396 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7457 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tfv_matrix.shape)\n",
    "tfv_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use our pairwise algorithm to compare the every element of the sparse matrix with every other element of the same sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = linear_kernel(tfv_matrix, tfv_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "       0.12050794])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build a basic recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(df.index, index=df['name']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Antojito Cantina                   300\n",
       "Lazeez Tandoori                    301\n",
       "Crazy Ivans                        302\n",
       "Dean Gallery Café                  303\n",
       "Joseph Pearce                      304\n",
       "Cafe Cassis                        305\n",
       "Serrano Manchego                   306\n",
       "Pierinos Take Away Food Shops      307\n",
       "Broughton Delicatessen and Café    308\n",
       "Lazy Lohans                        309\n",
       "On Tap Medina                      310\n",
       "Zazou Cruises                      311\n",
       "Spirit of Thai                     312\n",
       "Michelles Place                    313\n",
       "Frankie  Bennys                    314\n",
       "Jackson Restaurant                 315\n",
       "Zizzi                              316\n",
       "Buckstone Pub  Kitchen             317\n",
       "Dolphin Fish Bar                   318\n",
       "Usquabae                           319\n",
       "dtype: int64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[300:320]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices['Lazy Lohans'] #Check the correct index is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender(name, lin=lin):\n",
    "    \"\"\"\n",
    "    This function takes a restaurant title as an argument and \n",
    "    returns the n=5 most similar resstaurants based on the content\n",
    "    of the restaurant categories and the limnear similarity scores.  \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #First we get the index corresponding to the argument / original title\n",
    "    index = indices[name]\n",
    "    \n",
    "    #Then we fetch all the linear similarity scores for the pairwise comparisons \n",
    "    lin_scores = list(enumerate(lin[index]))\n",
    "    \n",
    "    #Now we sort the scores so the top recommended restaurants are at the top\n",
    "    sorted_lin_scores = sorted(lin_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    #give us a list equal to n=5\n",
    "    top_lin_scores = sorted_lin_scores[1:6]\n",
    "    \n",
    "    #Identify the restaurant indices corresponding to the above list\n",
    "    restaurant_index = [i[0] for i in top_lin_scores]\n",
    "    \n",
    "    #Now find the title names at these idices and return them as our recommendations!!\n",
    "    return df['name'].iloc[restaurant_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72        La Garrigue Bistro\n",
       "205           La PTite Folie\n",
       "299    Water of Leith Bistro\n",
       "324           Le Mouton Noir\n",
       "414              La Garrigue\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We call the recommender function with a restaurant that we want similar hits for!\n",
    "recommender('Martin Wishart') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Recommender - under construction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_int(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>business_ref</th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>categories</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>user_ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900</td>\n",
       "      <td>68</td>\n",
       "      <td>F31RycVVooeIOp9jsXmg6g</td>\n",
       "      <td>\"The Bluebird Cafe\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>Breakfast &amp; Brunch;Diners;Restaurants;Cafes;Br...</td>\n",
       "      <td>b31UZTy2TvnFtkfygJG40Q</td>\n",
       "      <td>bcxcQhp0sKYd9eUnEVUzPA</td>\n",
       "      <td>5</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>68</td>\n",
       "      <td>F31RycVVooeIOp9jsXmg6g</td>\n",
       "      <td>\"The Bluebird Cafe\"</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>Breakfast &amp; Brunch;Diners;Restaurants;Cafes;Br...</td>\n",
       "      <td>jYxWLyWrWy8dJFQs9DEuEg</td>\n",
       "      <td>RFxjYeLW_aYLdVW3PBwFNg</td>\n",
       "      <td>4</td>\n",
       "      <td>146572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  business_ref             business_id                 name  \\\n",
       "0        1900            68  F31RycVVooeIOp9jsXmg6g  \"The Bluebird Cafe\"   \n",
       "1        1901            68  F31RycVVooeIOp9jsXmg6g  \"The Bluebird Cafe\"   \n",
       "\n",
       "        city                                         categories  \\\n",
       "0  Edinburgh  Breakfast & Brunch;Diners;Restaurants;Cafes;Br...   \n",
       "1  Edinburgh  Breakfast & Brunch;Diners;Restaurants;Cafes;Br...   \n",
       "\n",
       "                review_id                 user_id  stars  user_ref  \n",
       "0  b31UZTy2TvnFtkfygJG40Q  bcxcQhp0sKYd9eUnEVUzPA      5       246  \n",
       "1  jYxWLyWrWy8dJFQs9DEuEg  RFxjYeLW_aYLdVW3PBwFNg      4    146572  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_df = df.copy()\n",
    "hybrid_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_map = hybrid_df.set_index('user_ref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arguments, userID == user_ref, name == restaurant_name\n",
    "def hybrid_recommender(userID, name):\n",
    "    indices_ = pd.Series(restaurants.index, index=restaurants['name'])\n",
    "    idx = indices_[name] #get index of the title\n",
    "    user_id = hybrid_df.loc[name]['user_ref'] # get user id of the review??\n",
    "    restaurant_id = id_map.loc[name]['business_ref'] #get business id of the review\n",
    "    \n",
    "    sim_scores = list(enumerate(lin[int(idx)]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:30]\n",
    "    restaurant_idx = [i[0] for i in sim_scores]\n",
    "    \n",
    "    restaurant = restaurants.iloc[restaurant_idx][['name', 'review_count', 'stars', 'business_ref', 'postal_code']]\n",
    "#     restaurant['pred'] = restaurant['id'].apply(lambda x: svd.predict(userID, indices_map.loc[x]['business_ref']).est)\n",
    "    \n",
    "    restaurant = restaurant.sort_vsalues('est', ascending=False)\n",
    "    return restaurant.head(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hybrid recommender under construction! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
